{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f8d549",
   "metadata": {},
   "source": [
    "<h1>APP WHISPER</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69df0316",
   "metadata": {},
   "source": [
    "<h3>1.- Install and Import</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2cba2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "!{sys.executable} -m pip install git+https://github.com/openai/whisper.git \n",
    "!{sys.executable} -m apt update && sudo apt install ffmpeg\n",
    "!{sys.executable} -m pip install librosa\n",
    "!{sys.executable} -m pip install gradio\n",
    "!{sys.executable} -m pip install pydantic\n",
    "!{sys.executable} -m pip install wget\n",
    "!{sys.executable} -m pip install torch\n",
    "!pip install markupsafe==2.0.1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c4c8f80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget\n",
    "import whisper\n",
    "import time\n",
    "import librosa\n",
    "import soundfile as sf\n",
    "import re\n",
    "import os\n",
    "import gradio as gr\n",
    "import time\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e747527",
   "metadata": {},
   "source": [
    "<h3>2.- Select the model and configuration</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70de313",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = whisper.load_model(\"tiny.en\")\n",
    "# model = whisper.load_model(\"base.en\")  \n",
    "# model = whisper.load_model(\"small\") # load the small model\n",
    "# model = whisper.load_model(\"medium.en\")\n",
    "model = whisper.load_model(\"large\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd59a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a147d7be",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c82d776c",
   "metadata": {},
   "source": [
    "<h3>3.- Transcription example</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d829e0a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "wget.download(\"http://www.moviesoundclips.net/movies1/darkknightrises/darkness.mp3\", \"audio.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e69da4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.transcribe(\"audio.mp3\")\n",
    "print(result[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f74c0a",
   "metadata": {},
   "source": [
    "<h3>4.- App for record and transcribe</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "430873f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference(audio):\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions(fp16 = False)\n",
    "    result = whisper.decode(model, mel, options)\n",
    "\n",
    "    # print the recognized text\n",
    "    print(result.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "61e71172",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unaiigartua/opt/anaconda3/lib/python3.8/site-packages/gradio/inputs.py:318: UserWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your components from gradio.components\n",
      "  warnings.warn(\n",
      "/Users/unaiigartua/opt/anaconda3/lib/python3.8/site-packages/gradio/deprecation.py:40: UserWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  warnings.warn(value)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hint: Set streaming=True for Audio component to use live streaming.\n",
      "Running on local URL:  http://127.0.0.1:7866\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7866/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(<gradio.routes.App at 0x7f8e69abd0a0>, 'http://127.0.0.1:7866/', None)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/unaiigartua/opt/anaconda3/lib/python3.8/site-packages/gradio/processing_utils.py:230: UserWarning: Trying to convert audio automatically from int32 to 16-bit int format.\n",
      "  warnings.warn(warning.format(data.dtype))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected language: en\n",
      "a Roski or Mercadona Has worked on the analysis on how the ambient conditions of the store for example the living Affect on the behavior of the customers So okay, so When we have to tackle a big data project going down\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    title = 'Whisper-app', \n",
    "    fn=inference, \n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"textbox\"\n",
    "    ],\n",
    "    live=True).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
